# This is the CUDA-enabled Docker image.
# See Dockerfile.worker-cpu for the CPU-only version.

# Stage 1: build
FROM nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04 AS builder

WORKDIR /build

# Build gRPC separately. PyTorch libraries blow up the image size substantially
# already (~ 1G IIRC), but (uncleaned) gRPC build artifacts are a whopping 3G.
RUN apt-get update && apt-get install -y \
    cmake \
    build-essential \
    curl \
    unzip \
    bzip2 \
    git \
    libssl-dev \
    && apt-get clean

# Build gRPC.

RUN git clone --recurse-submodules -b v1.66.0 --depth 1 --shallow-submodules https://github.com/grpc/grpc

RUN cd grpc \
    && mkdir -p cmake/build \
    && cd cmake/build \
    && cmake -DgRPC_INSTALL=ON -DgRPC_BUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=/opt ../.. \
    && make -j4 \
    && make install

RUN curl -L -O https://archives.boost.io/release/1.86.0/source/boost_1_86_0.tar.bz2 \
    && tar xjf boost_1_86_0.tar.bz2 \
    && cd boost_1_86_0/ \
    && ./bootstrap.sh --prefix=/opt \
    && ./b2 install

RUN curl -L -O https://github.com/jemalloc/jemalloc/releases/download/5.3.0/jemalloc-5.3.0.tar.bz2 \
    && tar xjf jemalloc-5.3.0.tar.bz2 \
    && rm jemalloc-5.3.0.tar.bz2 \
    && cd jemalloc-5.3.0 \
    && ./configure --prefix=/opt \
    && make \
    && make install \
    && cd .. \
    && ldconfig /opt/lib

RUN curl -L -o libtorch.zip https://download.pytorch.org/libtorch/cu121/libtorch-cxx11-abi-shared-with-deps-2.5.0%2Bcu121.zip \
    && unzip -d /opt libtorch.zip \
    && rm libtorch.zip

ENV CUDA_HOME=/usr/local/cuda

# Copy source files. Do this after required libraries were installed to avoid repeating that
# each time a source changes.
COPY ./cpp/ ./
COPY ./hexzpb/hexz.proto ./hexzpb/

RUN /opt/bin/protoc -Ihexzpb --cpp_out=. --grpc_out=. --plugin=protoc-gen-grpc=/opt/bin/grpc_cpp_plugin hexzpb/hexz.proto

RUN mkdir build \
    && cd build \
    && cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH="/opt/libtorch/share/cmake;/opt/lib/cmake" .. \
    && make -j4 worker

# Stage 2: final image
FROM nvidia/cuda:12.2.2-runtime-ubuntu22.04

WORKDIR /app

# Only copy relevant dynamic libs and the application binary.
COPY --from=builder /opt/lib/libjemalloc.so /opt/lib/libjemalloc.so
COPY --from=builder /opt/libtorch/lib /opt/libtorch/lib
COPY --from=builder /build/build/worker /app/worker

ENTRYPOINT ["/usr/bin/env", "LD_PRELOAD=/opt/lib/libjemalloc.so", "./worker"]
